# Neuroevolution Dodging Game

## Objectives
Development of a simple videogame and a neuroevolution algorithm to play it.

## Videogame
The videogame consists of a player placed at the bottom of the screen and giant blocks falling from the top of the screen. The player's objective is to avoid collision with those falling blocks by moving sideways. The player wins the game if it scores 100.000 points. Every frame the player is alive, it scores a point. If the player gets hit by a falling block, it dies and loses the game.

The player's and blocks' positions are tracked in a Cartesian coordinates system. These coordinates are going to be inputs of the neural network.

The videogame runs at 60 frames per second by default, meaning that a player gets a score of 100.000 points after playing for 27 minutes.
## Neural Network
### Model
The neural network model used in this project (Figure 1) consists of three layers: an input layer, which recieves gameplay information, a hidden layer, which helps in general processing and an output layer, which decides the actions that a player makes. The input layer receives four different inputs, the hidden layer has four fully connected perceptrons and the output layer gives three outputs. This neural network's diagram, without including the bias neural weights, is explained in Figure 1.

<p align="center">
  <img src="https://github.com/gnoya/Neuroevolution-Dodging-Game/blob/Readme/results/NeuralNetworkModel.png" width="500">
  </br>
  Figure 1: Neural network model.
</p>

'Player.x' refers to the X-axis position of the current player. 'Block.x' and 'Block.y' refer to X-axis and Y-axis position of the player's nearest block. Also, 'Block.width' represents the width of that block.

Focusing on the output layer, three options are given: move player to the left, move player to the right or don't move at all.

### Initialization
The weights between perceptrons were initialized randomly with values between -1 and 1. The bias weights were also initialized this way.

## Genetic Algorithms
These algorithms were implemented using a population of 350 players and a 0.05 mutation probability rate. The score represented how many frames the player lasted without dying. The fitness was calculated based on the score. The genes used were the weights of each neural network.

### Fitness
Every frame where a player was alive it scored a point. Then, after every player had died, every score was added up into a constant which divided every player's score resulting in its own fitness. This way, the sum of all fitnesses equals to 1.

### Natural Selection
A mating pool was created based on every player's fitness, meaning that players with higher fitness will be more likely to be picked. To create a new generation of players, two parents were picked randomly from this mating pool. Afterwards, the parents' genes were crossed and the child's genes had a chance of mutation.

### Crossover
The crossover algorithm implemented in this project is kind of rough. We chose two parents from the mating pool and named them ParentA and ParentB. Each parent has a neural network, and its simplified form is shown in Figure 2.

<p align="center">
  <img src="https://github.com/gnoya/Neuroevolution-Dodging-Game/blob/Readme/results/simpleModel.png" width="500">
  </br>
  Figure 2: Simplified neural network model.
</p>

Notice that this simplified diagram only has one weight between layers and only one weight for each bias, but in the real diagram, 'W.in', 'W.out', 'Bias.in' and 'Bias.out' are matrixes filled with weights. Weights between the input layer and the hidden layer were picked from Parent A (including bias weights), and weights between the hidden layer and the output layer were picked from Parent B. The child's neural network consisted on the crossover of both set of weights. An example of this is shown in Figure 3.

<p align="center">
  <img src="https://github.com/gnoya/Neuroevolution-Dodging-Game/blob/Readme/results/Crossover.png" width="500">
  </br>
  Figure 3: Crossover algorithm.
</p>

### Mutation
Mutation consisted on tweaking a weight from the neural network. For every weight in the neural network a random number between 0 and 1 was generated. If that random number was lower than the mutation rate, that particular weight mutated and its value was added to another random number generated by a Gaussian distribution with a mean of 0 and a standard deviation of 1.

## Experiment
With a population of 350 players, we ran the simulation five times over 150 generations. Figure 4 shows the highest achieved score versus its current generation focusing on the 100.000 score peak. That peak means that the player has achieved its goal.

<p align="center">
  <img src="https://github.com/gnoya/Neuroevolution-Dodging-Game/blob/Readme/results/resultschart1.png">
  </br>
  Figure 4: Results of neuroevolution focused on 100.000 score peak.
</p>

The highest scores for every generation vary. Figure 5 focuses on the highest score variation between generations.

<p align="center">
  <img src="https://github.com/gnoya/Neuroevolution-Dodging-Game/blob/Readme/results/resultschart2.png">
  </br>
  Figure 5: Results of neuroevolution focused on highest score variation.
</p>

## Results
A recorded video of the best player after 62 generations is included above.

[Neuroevolution - A player playing perfectly](https://youtu.be/LatdzqGKPz4)

## Conclusion
Even though the crossover function is rough and does not have a great performance, the neural network evolved and learned how to play the game because of the game's simplicity.

## Appendix
<p align="center">
  <img src="https://github.com/gnoya/Neuroevolution-Dodging-Game/blob/Readme/results/training.png" width="500">
  </br>
  Figure 6: Simulated training process.
</p>

<p align="center">
  <img src="https://github.com/gnoya/Neuroevolution-Dodging-Game/blob/Readme/results/showingBest.png" width="500">
  </br>
  Figure 7: Best player playing the game.
</p>

## Built with
[P5.js](https://github.com/processing/p5.js "P5.js library")

[Toy-Neural-Network-JS](https://github.com/CodingTrain/Toy-Neural-Network-JS "Toy Nerual Network library")

## How to use
Download this repository and run index.html. If you want a faster training, you can speed up the process by moving the speed slider. For faster training, check the 'Not draw' box. If you want to show the best player so far, check the 'Show best' box. If you wish to download the best player's neural network, click on 'Download best neural network' and a JSON file will be downloaded.

## TODO
Add a way to load a neural network into the game.

Use / develop another crossover algorithm and test its performance.
